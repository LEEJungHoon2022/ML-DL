{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8820912e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:39.723463Z",
     "iopub.status.busy": "2022-06-25T13:35:39.723010Z",
     "iopub.status.idle": "2022-06-25T13:35:39.736389Z",
     "shell.execute_reply": "2022-06-25T13:35:39.735606Z"
    },
    "papermill": {
     "duration": 0.028394,
     "end_time": "2022-06-25T13:35:39.738857",
     "exception": false,
     "start_time": "2022-06-25T13:35:39.710463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c9602",
   "metadata": {
    "papermill": {
     "duration": 0.008492,
     "end_time": "2022-06-25T13:35:39.756508",
     "exception": false,
     "start_time": "2022-06-25T13:35:39.748016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 주요 머신러닝 모델\n",
    "### 캐글에서 가장 인기있는 머신러닝 모델은 XGBoost와 LightGBM임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c4bcb",
   "metadata": {
    "papermill": {
     "duration": 0.008755,
     "end_time": "2022-06-25T13:35:39.774078",
     "exception": false,
     "start_time": "2022-06-25T13:35:39.765323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 선형 회귀 모델은 선형 회귀식을 활용한 모델이다 -> 훈련데이터에 잘맞는 모델 파라미터, 즉 회귀계수를 찾는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708b9b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:39.793872Z",
     "iopub.status.busy": "2022-06-25T13:35:39.793284Z",
     "iopub.status.idle": "2022-06-25T13:35:40.039873Z",
     "shell.execute_reply": "2022-06-25T13:35:40.038838Z"
    },
    "papermill": {
     "duration": 0.259395,
     "end_time": "2022-06-25T13:35:40.042247",
     "exception": false,
     "start_time": "2022-06-25T13:35:39.782852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ffaf4ca5f10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 생성\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0) # 시드 값 고정\n",
    "\n",
    "w0 = 5 # y절편\n",
    "w1 = 2 # 회귀계수\n",
    "noise = np.random.randn(100,1) # 노이즈\n",
    "\n",
    "x = 4 * np.random.rand(100,1) # 0~4 사이의 실수값 100개 생성(x값)\n",
    "y = w1*x +w0 + noise # y값\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46b0a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:40.063743Z",
     "iopub.status.busy": "2022-06-25T13:35:40.063354Z",
     "iopub.status.idle": "2022-06-25T13:35:41.327364Z",
     "shell.execute_reply": "2022-06-25T13:35:41.326207Z"
    },
    "papermill": {
     "duration": 1.278546,
     "end_time": "2022-06-25T13:35:41.330535",
     "exception": false,
     "start_time": "2022-06-25T13:35:40.051989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기 : [[1.9808382]]\n",
      "y 절편 : [5.09772262]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_reg_model = LinearRegression() # 선형 회귀 모델\n",
    "linear_reg_model.fit(x,y) # 모델 훈련\n",
    "\n",
    "print('기울기 :', linear_reg_model.coef_)\n",
    "print('y 절편 :', linear_reg_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc8f616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:41.352245Z",
     "iopub.status.busy": "2022-06-25T13:35:41.351107Z",
     "iopub.status.idle": "2022-06-25T13:35:41.554094Z",
     "shell.execute_reply": "2022-06-25T13:35:41.552517Z"
    },
    "papermill": {
     "duration": 0.217059,
     "end_time": "2022-06-25T13:35:41.557347",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.340288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffacfde2250>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_predict = linear_reg_model.predict(x) # 예측\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x, y_predict) # 선형 회귀선 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6d497",
   "metadata": {
    "papermill": {
     "duration": 0.010051,
     "end_time": "2022-06-25T13:35:41.579628",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.569577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 로지스틱 회귀 모델\n",
    "\n",
    "### 선형 회귀 방식을 응용해 분류에 적용한 모델\n",
    "### 시그모이드 함수 활용하여 타깃값에 포함될 확률을 예측\n",
    "### 0과 1사이의 값을 가짐 x 값(확률)이 0.5보다 작으면 음성 0.5이상이면 양성이라고 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee6cfe",
   "metadata": {
    "papermill": {
     "duration": 0.009963,
     "end_time": "2022-06-25T13:35:41.599844",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.589881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 결정 트리\n",
    "### 분류와 회귀 문제에 모두 사용 가능한 모델\n",
    "\n",
    "#### 1. 우선 데이터를 가장 잘 구분하는 조건을 정함\n",
    "#### 2. 조건을 기준으로 데이터를 두 범주로 나눔\n",
    "#### 3. 나뉜 각 범주에 속할 데이터를 다시 분할합니다.\n",
    "#### 4. 조건에 따라 각 범주에 속한 데이터를 다시 분할합니다.\n",
    "#### 5. 이런 식으로 계속 분할해 최종 결정 값을 구함\n",
    "\n",
    "### 결정 트리에서 첫 번째 노드를 뿌리노드(root node) 조건이 담긴 중간층 노드를 중간노드(intermediate node)\n",
    "### 결정 값이 담긴 마지막 노드를 말단 노드(leaf node)라고 함\n",
    "\n",
    "## 결정 트리 분할 방식\n",
    "### 결정 트리를 만들 때는 분할 조건이 중요하다. 조건에 따라 분할 후 만들어지는 트리모양(과 동작 효율)이 다르기 때문임.\n",
    "\n",
    "## 머신러닝 에서 결정트리가 데이터를 분할하는 방식\n",
    "### 노드 내 데이터의 불순도를 최소화하는 방향으로 분할한다. \n",
    "### 불순도(impurity)는 한 범주 안에 서로 다른 데이터가 얼마나 섞여있는지 나타냄\n",
    "\n",
    "## 불순도를 측정하는 지표\n",
    "### 엔트로피(entropy)\n",
    "\n",
    "#### 엔트로피(entropy)란 불확실한 정도를 뜻함 정렬이 잘되어있을 수록 0에 가까워지고 정렬이 안되어있을 수록 1에 가까움\n",
    "#### 결정트리는 정보 이득(information gain)을 최대화 하는 방향으로 노드를 분할함\n",
    "\n",
    "### 지니 불순도\n",
    "#### 엔트로피와 비슷한 개념임. 지니 불순도의 값이 클수록 불순도가 높고, 작을수록 불순도도 낮음 엔트로피와 마찬가지로 지니 불순도가 낮아지는 방향으로 노드를 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d926b8",
   "metadata": {
    "papermill": {
     "duration": 0.009971,
     "end_time": "2022-06-25T13:35:41.620065",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.610094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 결정 트리 구현\n",
    "## 분류형 모델 : DecisionTreeClassifier\n",
    "## 회귀형 모델 : DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0511d57",
   "metadata": {
    "papermill": {
     "duration": 0.010003,
     "end_time": "2022-06-25T13:35:41.640074",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.630071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DeisionTreeClassifier를 기준으로 결정 트리 구현\n",
    "\n",
    "### criterion : 분할 시 사용할 불순도 측정 지표\n",
    "#### 'gini'를 전달하면 지니 불순도를 활용해 분할\n",
    "#### 'entropy'를 전달하면 정보 이득(information gain) 방법으로 분할\n",
    "#### 기본값 = 'gini'\n",
    "\n",
    "### max_depth : 트리의 최대 깊이\n",
    "#### max_depthㄹ르 규정하지 않으면 모들 말단 노드의 불순도가 0이 되거나 노드의 있는 데이터 수가 min_sample_split보다 작을 때까지 트리 깊이가 깊어짐\n",
    "#### 기본값 = 'None'\n",
    "\n",
    "## min_samples_split : 노드 분할을 위한 최소 데이터 개수\n",
    "#### 노드 내 데이터 개수가 이 값보다 작으면 더 이상 분할하지 않음\n",
    "#### 정수형으로 전달하면 최소 데이터 개수를 의미함\n",
    "#### 실수형으로 전달하면 전체 데이터 개수 중 최소 데이터 개수 비율을 의미. ex) 전체 데이터수 100, min_samples_split = 0.1 node = 100 * 01 = 10(데이터 10개가 노드 분할을 위한 최소 데이터 개수) 기본값 = 2\n",
    "\n",
    "## min_samples_leaf : 말단 노드가 되기 위한 최소 데이터 개수\n",
    "#### 분할 후 노드 내 데이터 개수가 이 값보다 작으면 더 이상 분할하지 않음\n",
    "#### 정수형으로 전달하면 최소 데이터 개수를 의미\n",
    "#### 실수형으로 전달하면 전체 데이터 개수 중 최소 데이터 개수 비율을 의미\n",
    "#### 기본 값 = 1\n",
    "\n",
    "## max_features : 분할에 사용할 피처 개수\n",
    "#### 정수형으로 전달하면 피처 개수를 의미\n",
    "#### 실수형으로 전달하면 전체 피처 개수 중 분할에 사용될 피처 개수 비율을 의미\n",
    "#### 'auto'나 'sqrt'를 전달하면 sqrt(전체 피처 개수)가 분할에 사용될 피처 개수임\n",
    "#### 'log2'를 전달하면 log2(전체 피처 개수)가 분할에 사용될 피처 개수임\n",
    "#### None을 전달하면 전체 피처를 분할에 사용\n",
    "#### 기본값 = None\n",
    "\n",
    "### 결정 트리에 조건이 많을수록 분할이 많고 트리가 깊어짐, 분할을 지나치게 많이 하면 모델이 과대적합될 우려가 있으니 파라미터를 잘 조절해야 함.\n",
    "#### max_depth, min_samples_split, min_samples_leaf가 결정트리의 과대적합을 제어하는 파라미터임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07667859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:41.664778Z",
     "iopub.status.busy": "2022-06-25T13:35:41.664198Z",
     "iopub.status.idle": "2022-06-25T13:35:41.866082Z",
     "shell.execute_reply": "2022-06-25T13:35:41.864648Z"
    },
    "papermill": {
     "duration": 0.218578,
     "end_time": "2022-06-25T13:35:41.869408",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.650830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 트리 점수 : 0.93\n"
     ]
    }
   ],
   "source": [
    "# 유방암 데이터셋으로 결정 트리 모델의 정확도를 측정하는 코드\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 유방암 데이터셋 불러오기\n",
    "cancer_data = load_breast_cancer() # cancer_data 인스턴스 생성\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( # train, test로 데이터 분할\n",
    "    cancer_data['data'],\n",
    "    cancer_data['target'],\n",
    "    stratify=cancer_data['target'], # y_test에 입력되는 데이터 비율 조절\n",
    "    test_size=0.4,\n",
    "    random_state=42) # 시드 고정\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42) # 결정 트리 정의\n",
    "decision_tree.fit(X_train, y_train) # 모델 훈련\n",
    "\n",
    "accuracy = decision_tree.score(X_test, y_test)\n",
    "print(\"결정 트리 점수 : {}\".format(round(accuracy,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3dfa92",
   "metadata": {
    "papermill": {
     "duration": 0.009976,
     "end_time": "2022-06-25T13:35:41.889630",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.879654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 앙상블 학습\n",
    "\n",
    "### 다양한 모델이 내린 예측 결과를 결합하는 기법을 앙상블 학습(ensumble learning)이라고 함\n",
    "### 앙상블 학습을 활용하면 대체로 예측 성능이 좋아짐, 과대적합 방지 효과도 있음 // 캐글러들은 앙상블 기법을 많이 활용함\n",
    "\n",
    "### 앙상블 학습 유형으로는 보팅, 배깅, 부스팅 등이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828bc09",
   "metadata": {
    "papermill": {
     "duration": 0.009854,
     "end_time": "2022-06-25T13:35:41.909572",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.899718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 보팅\n",
    "#### 서로 다른 모델로 예측한 결과가 여럿 있다고 가정했을 때 개별 결과를 종합해 최종 결과를 결정하는 방식을 보팅(voting)이라고 함 // 보팅 기법은 하드, 소프트 보팅으로 나눠짐\n",
    "#### 하드 보팅(hard voting)은 '다수결 투표' 방식으로 최종 예측값을 정함\n",
    "#### 소프트 보팅(soft voting)은 개별 예측 확률들의 평균을 최종 예측 확률로 정하는 방식\n",
    "### 일반적으로는 하드 보팅보다 소프트 보팅이 성능이 좋아 대체로 소프트 보팅을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272d831",
   "metadata": {
    "papermill": {
     "duration": 0.009902,
     "end_time": "2022-06-25T13:35:41.929628",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.919726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 배깅\n",
    "\n",
    "#### 배깅(bagging : 봉지(가방 등)에 담다)은 개별 모델로 예측한 결과를 결합해 최종 예측을 정하는 기법임\n",
    "#### 배깅의 특징은 '개별 모델이 서로 다른 샘플링 데이터를 활용' 한다는 점\n",
    "##### 1. 전체 훈련 데이터셋에서 무작위 샘플링한 데이터로 개별 모델을 훈련함\n",
    "##### 2. 훈련된 개별 모델로 결과를 예측함\n",
    "##### 3. 개별 모델의 수만큼 1~2번 작업을 반복함\n",
    "##### 4. 각 모델이 예측한 값들을 보팅하여 최종 예측값을 구함\n",
    "### 배깅은 원리가 간단하면서도 성능을 높일 수 있는 효과적인 기법임 // 배깅 기법을 활용한 대표적인 모델이 랜덤 포레스트임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d4e52",
   "metadata": {
    "papermill": {
     "duration": 0.009934,
     "end_time": "2022-06-25T13:35:41.949657",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.939723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 부스팅(boostiong : 복돋우다)은 가중치를 활용해 분류 성능이 약한 모델을 강하게 만드는 기법임.\n",
    "#### 모델 간 협력이 이루어짐 ex) 이전 모델이 잘못 예측한 값의 가중치를 부여하여 다음 모델은 이전 모델의 잘못 예측한 데아터(가중치가 부여된 데이터)에 더 집중해 훈련함\n",
    "#### 가중치가 부여된 데이터를 그만큼 더 중요하다고 판단해 더 잘 분류하려고 함 // 이런 단계를 반복하면 모델 성능이 점차 향상 됨(자세한 동작은 148p 참고)\n",
    "#### 개별 분류 모델을 여러개 만들어 결합하는 방법\n",
    "\n",
    "### 부스팅 기법을 활용한 대표적인 모델 : XGBoost, LightGBM 등이 있"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511d10b",
   "metadata": {
    "papermill": {
     "duration": 0.009813,
     "end_time": "2022-06-25T13:35:41.969567",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.959754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 랜덤 포레스트\n",
    "\n",
    "### 결정 트리를 배깅 방식으로 결합한 모델임.\n",
    "### 나무가 모여 숲을 이루듯 결정 트리가 모여 랜덤 포레스트를 구성함 결정 트리와 마찬가지로 랜덤 포레스트도 분류와 회귀 문제에 모두 적용 가능\n",
    "### 결정 트리를 배깅 방식으로 결합해 랜덤 포레스트를 만들 수 있음(자세한 동작은 150p 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3fcd3",
   "metadata": {
    "papermill": {
     "duration": 0.01006,
     "end_time": "2022-06-25T13:35:41.990319",
     "exception": false,
     "start_time": "2022-06-25T13:35:41.980259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 랜덤 포레스트 구현\n",
    "#### 분류 모델은 RandomForestClassifier\n",
    "#### 회귀 모델은 RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135dbb1",
   "metadata": {
    "papermill": {
     "duration": 0.009961,
     "end_time": "2022-06-25T13:35:42.010445",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.000484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RandomForestClassifier의 파라미터\n",
    "#### n_estimators : 랜덤 포레스트를 구성할 결정 트리 개수 // 기본값 100\n",
    "#### criterion : 분할 시 사용할 불순도 측정 지표 // 세부 내용은 DecisionTreeClassifier와 동일\n",
    "#### max_depth : 트리의 최대 깊이 // 세부 내용은 DecisionTreeClassifier와 동일\n",
    "#### min_samples_split : 노드 분할을 위한 최소 데이터 개수 // 세부 내용은 DecisionTreeClassifier와 동일\n",
    "#### min_samples_leaf : 말단 노드가 되기위한 최소 데이터 개수 // 세부 내용은 DecisionTreeClassifier와 동일\n",
    "#### max_features : 분할에 사용할 피처 개수 // 세부 내용은 DecisionTreeClassifier와 동일 // 기본값 : 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9bae9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:42.032439Z",
     "iopub.status.busy": "2022-06-25T13:35:42.032020Z",
     "iopub.status.idle": "2022-06-25T13:35:42.348395Z",
     "shell.execute_reply": "2022-06-25T13:35:42.347534Z"
    },
    "papermill": {
     "duration": 0.330467,
     "end_time": "2022-06-25T13:35:42.350940",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.020473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier 구현\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# 훈련, 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    breast_cancer['data'],\n",
    "    breast_cancer['target'],\n",
    "    stratify=breast_cancer['target'],\n",
    "    test_size = 0.4,\n",
    "    random_state=42)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "random_forest.score(X_test, y_test) # 결정 트리 때보다 점수가 조금 더 올라감"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa513289",
   "metadata": {
    "papermill": {
     "duration": 0.010071,
     "end_time": "2022-06-25T13:35:42.371401",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.361330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBoost\n",
    "### 성능이 우수한 트리 기반 부스팅 알고리즘임. // 많은 캐글 우승자가 XGBoost를 사용함\n",
    "### 랜덤 포레스트는 결정 트리를 병렬로 배치하지만. XGBoost는 직렬로 배치해 사용함, 즉 랜덤 포레스트는 배깅 방식, XGBoost는 부스팅 방식임\n",
    "### 부스팅 방식이므로 직전 트리가 예측한 값을 다음 트리가 활용해서 예측값을 조금씩 수정합니다.\n",
    "\n",
    "### XGBoost의 주요 모듈은 C와 C++로 작성 되었지만 파이썬으로도 XGBoost를 사용할 수 있게 API를 제공함\n",
    "### 이책에서는 파이썬 래퍼로 XGBoost를 설명함 // 별도의 데이터셋을 생성해야 됨 // DMatrix 객체를 활용해 XGBoost 전용 데이터 셋을 만들어야됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb207f2",
   "metadata": {
    "papermill": {
     "duration": 0.010078,
     "end_time": "2022-06-25T13:35:42.391616",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.381538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## xgboost.DMatrix() 파라미터\n",
    "#### data : xgboost.DMatrix용 데이터 셋 넘파이 배열, 판다스 DataFrame, scipy.sparse, os.PathLike, 문자열 타입을 전달 할 수 있음(os.PathLike나 문자열이면 데이터 경로를 의미)\n",
    "#### label : 타깃값 // 배열 타입을 전달 할 수 있음\n",
    "\n",
    "## XGBoost 모델은 하이퍼 파라미터가 많음 주로 사용히는 파라미터는 아래와 같음 // 이 하이퍼파라미터들은 딕셔너리 형태로 train()매서드의 params 파라미터에 전달하면 됨(XGBoost 1.4.2 기준)\n",
    "\n",
    "### booster : 부스팅 알고리즘 // 트리 기반 모델일 때는 'gbtree', 'dart' 를 선택하고, 선형 모델일 때는 'gblinear'를 선택\n",
    "#### ('gblinear'는 성능이 나빠 잘 쓰지 않음. 'dart'는 드롭 아웃을 적용한 'gbtree'라고보면 됨. 때에 따라 'dart'가 성능이 좋은 경우가 있음)\n",
    "#### 기본값 = 'gbtree'\n",
    "\n",
    "### objective : 훈련 목적 \n",
    "#### 회귀 문제에서는 주로 'reg:squarederror'를 사용\n",
    "#### 확률 값을 구하는 이진 분류에서는 'multi:softmax'를 사용\n",
    "#### 확률 값을 구하는 다중 분류에서는 'multi:softprob'를 사용\n",
    "#### 기본값 = 'reg:squarederror'\n",
    "\n",
    "### eta(learning_rate) : 학습률(부스팅 스템을 반복하면서 모델을 업데이트 하는데 사용되는 비율)\n",
    "#### 0~1 사이의 값으로 설정 할 수 있으며. 일반적으로 0.0001 ~ 0.1 사이 값을 시용 // 기본값 : 0.3\n",
    "\n",
    "### max_depth : 개별 트리의 최대 깊이\n",
    "#### 과대적합을 제어하는 파라미터\n",
    "#### 트리 깊이가 깊을수록 모델이 복잡해지고 과대적합 될 우려가 있음\n",
    "#### 일반적으로 3~10 사이에 값을 주로 사용\n",
    "#### 값이 클수록 깊이가 한 단계만 늘어나도 메모리 사용량이 급격히 많아짐(값이 클수록 모델 훈련속도가 느려진다는 뜻) // 기본값 = 6\n",
    "\n",
    "### subsample : 개별 트리를 훈련할 때 사용할 데이터 샘플링 비율\n",
    "#### 0 ~ 1 사이 값으로 설정할 수 있음\n",
    "#### 0.5로 설정하면 전체 데이터의 50%를 사용해 트리를 생성\n",
    "#### 일반적으로 0.6 ~ 1사이 값을 사용. 더 작으면 샘플링 할 데이터가 너무 적기 때문\n",
    "#### 기본값 = 1\n",
    "\n",
    "### colsample_bytree : 개별 트리를 훈련할 때 사용하는 피처 샘플링 비율\n",
    "#### 0~1 사이 값으로 설정할 수 있음\n",
    "#### subsample과 유사한 개념. subsample은 전체 데이터에서 얼마나 샘플링할지 나타내는 비율이고, colsample_bytree는 전체 피처에서 얼마나 샘플링할지 나타내는 비율\n",
    "#### 예를 들어, colsample_bytree의 값이 0.7이면, 개별 트리를 훈련할 때 총 피처의 70%만 사용해 훈련\n",
    "#### 값이 작을수록 과대적합 방지 효과가 있음\n",
    "#### subsample과 마찬가지로 0.6~1 사이 값을 주로 사용\n",
    "#### 기본값 = 1\n",
    "\n",
    "### alpha (reg_alpha) : L1 규제 조정 값\n",
    "#### 값이 클수록 과대적합 방지 효과가 있음\n",
    "#### 기본값 = 0\n",
    "\n",
    "### lambda(reg_lambda) : L2 규제 조정 값\n",
    "#### 파이썬 lambda 함수와 용어가 같아 혼동을 피하기 위해 별칭인 reg_lambda를 주로 사용\n",
    "#### 값이 클수록 과대적합 방지 효과가 있음\n",
    "#### 기본값 = 1\n",
    "\n",
    "### gamma (min_split_loss) : 말단 노드가 분할하기 위한 최소 손실 감소 값\n",
    "#### 0 이상 값으로 설정할 수 있음\n",
    "#### 손실 감소가 gamma보다 크면 말단 노드를 분할\n",
    "#### 값이 클수록 과대적합 방지 효과가 있음\n",
    "#### 기본값 = 0\n",
    "\n",
    "### min_child_weight : 과대적합 방지를 위한 값\n",
    "#### 0 이상 값으로 설정할 수 있음\n",
    "#### 값이 클수록 과대 적합 방지 효과가 있음\n",
    "#### 기본값 = 1\n",
    "\n",
    "### scale_pos_weight : 불균형 데이터 가중치 조정 값\n",
    "#### 타깃값이 불균형 할 때 양성(positive) 값에 scale_pos_weight만큼 가중치를 줘서 균형을 맞춤(타깃값 1을 양성 값으로 간주)\n",
    "#### 일반적으로 scale_pos_weight 값을(음성 타깃값 개수/ 양성 타깃값 개수)로 설정\n",
    "#### 기본값 = 1\n",
    "\n",
    "### random_state : 랜덤 시드 값(코드를 반복 실행해도 같은 결과가 나오게 지정하는 값)\n",
    "#### 가본값 =  None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea25ea",
   "metadata": {
    "papermill": {
     "duration": 0.009785,
     "end_time": "2022-06-25T13:35:42.411529",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.401744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 파이썬 래퍼 XGBoost는 모델 훈련을 위해 train() 매서드를 제공함(사이킷런의 .fit()메서드에 해당) xgboost.train()의 파라미터는 다음과 같음\n",
    "\n",
    "### params : XGBoost 모델의 하이퍼 파라미터 목록\n",
    "#### 딕셔너리 타입으로 전달\n",
    "\n",
    "### dtrain : 훈련 데이터 셋\n",
    "#### xgboost.DMatrix 타입으로 전달\n",
    "\n",
    "### num_boost_round : 부스팅 반복 횟수\n",
    "#### 정수형 타입으로 전달\n",
    "#### num_boost_round 값이 클수록 성능이 좋아질 수 있으나 과대적합 우려가 있음\n",
    "#### num_boost_round 값이 작으면 반복 횟수가 줄어들어 훈련시간이 짧아짐\n",
    "#### 일반적으로 num_boost_round를 늘리면 learing_rate를 줄여야 함\n",
    "#### 기본값 = 10\n",
    "\n",
    "### evals = 모델 성능 평가용 검증 데이터셋\n",
    "#### (Dmatrix, 문자열) 쌍들을 원소로 갖는 리스트 타입으로 전달. 검증 데이터셋 이름을 원하는 대로 문자열을 정하면 됨\n",
    "#### 훈련을 반복하면서 훈련이 잘 되고 있는지 평가할 때 사용\n",
    "#### 기본값 = 빈 배열\n",
    "\n",
    "### feval : 검증용 평가지표\n",
    "#### 사용자 정의 함수 형태로 전달\n",
    "#### evals를 활용해 모델 성능을 검증 할 때 사용할 사용자 정의 평가지표 함수\n",
    "#### 예측값과 실제값을 파라미터로 전달받아, 평가 지표명과 평가 점수를 반환하는 함수여야 함\n",
    "#### 기본값 = None\n",
    "\n",
    "### maximize : feval 평가점수가 높으면 좋은지 여부\n",
    "#### True 또는 False 형태로 전달\n",
    "\n",
    "### early_stopping_rounds : 조기종료 조건\n",
    "#### 정수형 타입으로 전달\n",
    "#### 모델은 기본적으로 num_boost_round만큼 훈련을 반복하며, 매 이터레이션마다 evals로 모델 성능을 평가하여 성능이 연속적으로 좋아지지 않는 다면 훈련을 중단하는데,\n",
    "#### 훈련 중단에 필요한 최소 횟수가 early_stopping_rounds임 즉 early_stopping_rounds동안 모델 성능이 좋아지지 않는다면 훈련을 중단\n",
    "#### 과대적합을 방지하는 효과가 있음\n",
    "#### 조기 종료를 적용하려면 evals에 검증 데이터가 하나 이상 있어야 함 또한, evals에 검증 데이터가 여러개라면 마지막 검증 데이터를 기준으로 조기 종료 조건을 적용\n",
    "#### 대체로 eta가 작으면 early_stopping_rounds를 크게 설정하고, eta가 크면 작게 설정 학습률이 작으면 그만큼 가중치가 천천히 갱신되므로 조기 종료 조건이 커야 함\n",
    "#### 기본값 : None\n",
    "\n",
    "### verbose_eval : 성능 점수 로그 설정 값\n",
    "#### True/False 또는 정수형 타입으로 전달\n",
    "#### True로 설정하면 매 부스팅 스텝마다 평가 점수를 출력(False면 출력하지 않음)\n",
    "#### 정수면 평가점수를 매 verbose_eval 스텝마다 출력, 예컨대, verbose_eval을 100으로 설정하면 100번,200번,300번과 같이 띄엄띄엄 출력\n",
    "#### 출력값이 너무 많아지는 걸 방지하려고 verbose_eval을 설정\n",
    "#### 기본값 = True\n",
    "\n",
    "\n",
    "## 파라미터가 매우 많지만 전부 숙지하려하지말고 기본적인 파라미터에 익숙해지면 점차 늘려가는 방식으로 학습 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444ae6d",
   "metadata": {
    "papermill": {
     "duration": 0.009872,
     "end_time": "2022-06-25T13:35:42.431630",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.421758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LightGBM\n",
    "### 마이크로소프트에서 개발한 LightGBM은 XGBoost와 더불어 성능이 우수한 알고리즘임.\n",
    "### XGBoost와 성능은 비슷하지만 훈련속도가 더 빨라서 많이 사용\n",
    "### LightGBM 분할 방식\n",
    "### 대부분 트리 기반 모델은 트리를 균형있게 분할하며 훈련함. 그래야 트리 깊이가 최소화되고, 과대적합도 방지할 수 있기 때문 하지만 균형을 유지하려면 추가 연산이 필요(시간이 더 소요됨)\n",
    "### 반면, LightGBM은 말단 노드 중심으로 예측 오류를 최소화하게끔 분할함. 말단 노드 중심으로 분할 하면 균형을 유지할 필요가 없음 // 균형을 맞출 필요가 없어 추가 연산 필요 X // 따라서 균형 중심 분할에 비해 속도가 빠름\n",
    "### 하지만 데이터 개수가 적을 때는 과대적합 되기 쉽다는 단점이 생겨 과대적합 방지용 하이퍼파라미터를 조정해줘야 함(모델의 구조는 157p 참고)\n",
    "\n",
    "### LightGBM은 XGBoost와 마찬가지로 파이썬 래퍼 모듈과 사이킷런 래퍼 모듈이 있음 여기서는 파이썬 래퍼 LigthGBM으로 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515fe38",
   "metadata": {
    "papermill": {
     "duration": 0.009838,
     "end_time": "2022-06-25T13:35:42.451334",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.441496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## XGBoost와 LightGBM의 특장점\n",
    "#### 1. 피처 스케일링이 따로 필요 없음 데이터의 절대적인 크기보다는 대소 관계에 영향을 받기 때문\n",
    "#### 2. 레이블 인코딩을 적용해도 됨. 레이블 인코딩은 단점이 있지만, 트리 기반 모델의 특성상 분기를 거듭하면서 레이블 인코딩된 피처에서도 정보를 잘 추출할 수 있기 때문\n",
    "#### 3. 결측값을 알아서 처리해줌(그럼에도 더 명확하게 하려면 결측값을 별도로 처리하는 습관을 들이는게 바람직함.)\n",
    "\n",
    "### 반면 선형모델은 피처 스케일링, 결측값 처리, 원-핫 인코딩을 해줘야 일반적으로 성능이 좋아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66d1d0",
   "metadata": {
    "papermill": {
     "duration": 0.009586,
     "end_time": "2022-06-25T13:35:42.470925",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.461339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 파이썬 래퍼 LightGBM을 사용하려면 lightgbm.Dataset()으로 전용 데이터 셋을 만들어야 함, lightgbm.Dataset() 파라미터는 다음과 같음\n",
    "\n",
    "### data : lightgbm.Dataset용 데이터 셋\n",
    "#### 넘파이 배열, 판다스 DataFrame, scipy sparse, 문자열 등의 타입을 전달할 수 있음(문자열이면 파일 경로를 의미)\n",
    "\n",
    "### label : 타깃값\n",
    "#### 리스트, 넘파이 1차원 배열, 판다스 Series, 열이 하나인 DataFrame 타입 또는 None을 전달할 수 있음 // 기본값 = None\n",
    "\n",
    "## 파이썬 래퍼 LightGBM 모델에서 주로 사용하는 하이퍼 파라미터들(LightGBM 3.2.1 버전 기준)\n",
    "### Boostiong_type: 부스팅 알고리즘\n",
    "#### 알고리즘 종류는 'gbdt','dart','goss','rf'가 있음\n",
    "#### 기본값 = 'gbdt'\n",
    "\n",
    "### objective : 훈련 목적\n",
    "#### 회귀에서는 'regression', 이진 분류에선 'binary', 다중분류에선 'multiclass' 사용\n",
    "#### 기본값 = 'regression'\n",
    "\n",
    "### learning_rate(eta) : 학습률(부스팅 이터레이션을 반복하면서 모델을 업데이트하는 데 사용되는 비율)\n",
    "#### XGBoost의 eta와 같은 의미\n",
    "\n",
    "### num_leaves : 개별 트리가 가질 수 있는 최대 말단 노드 개수\n",
    "#### 트리 복잡도를 결정하는 주요 파라미터\n",
    "#### 값이 클수록 성능이 좋아질 수 잇으나 과대적합 우려가 있음\n",
    "#### 기본값 : 31\n",
    "\n",
    "### max_depth : 개별 트리의 최대 깊이\n",
    "#### LightGBM은 말단 노드 중심으로 분할하므로 max_depth를 균형 중심 분할 모델(XGBoost)보다 크게 잡는 게 좋음\n",
    "#### 과대적합 제어 파라미터\n",
    "#### 트리 깊이가 깊을수록 모델이 복잡해지고 과대적합될 우려가 있음\n",
    "#### 기본값 -1 (0보다 작으면 깊이에 제한이 없음)\n",
    "\n",
    "### bagging_fraction(subsample) : 개별 트리를 훈련할 때 사용할 데이터 샘플링 비율\n",
    "#### xgboost의 subsample 파라미터와 같은 의미\n",
    "#### 배깅을 활성화하려면 bagging_freq 파라미터를 0이 아닌값으로 설정 해야 함\n",
    "\n",
    "### feature_fraction(colsample_bytree) : 개별 트리를 훈련할 때 사용하는 피처 샘플링 비율\n",
    "#### xgboost의 colsample_bytree 파라미터와 같은 의미\n",
    "\n",
    "### lambda_l1(reg_alpha) : L1 규제 조정값\n",
    "#### 값이 클수록 과대적합 방지 효과가 있음\n",
    "#### 기본값 = 0\n",
    "\n",
    "### lambda_l2(reg_lambda) : L2 규제 조정 값\n",
    "#### 값이 클수록 과대적합 방지 효과가 있음\n",
    "#### 가본값 = 0\n",
    "\n",
    "### min_child_samples : 말단 노드가 되기 위해 필요한 최소 데이터 개수\n",
    "#### 값이 클수록 과대적합 방지 효과가 있음\n",
    "#### 기본값 = 20\n",
    "\n",
    "### min_child_weight : 과대적합 방지를 위한 값\n",
    "#### 0 이상 값으로 설정할 수 있음\n",
    "#### 값이 클수록 과대적합 방지 효과가 있음\n",
    "#### 기본값 : 1e-3\n",
    "\n",
    "### begging_freq(subsample_freq) : 배깅 수행 빈도\n",
    "#### 몇 번의 이터레이션마다 배깅을 수행할지 결정\n",
    "#### 0 전달 시 배깅을 수행하지 않음\n",
    "#### 1 전달 시 매 이터레이션마다 트리가 새로운 샘플링 데이터로 학습\n",
    "#### 기본값 = 0\n",
    "\n",
    "### force_row_wise : 메모리 용량이 충분하지 않을 때 메모리 효율을 높이는 파라미터\n",
    "#### 메모리 용량이 충분하지 않을 때 True를 전달하면 메모리 효율이 좋아짐\n",
    "#### 기본값 = False\n",
    "\n",
    "### random_state : 랜덤 시드값\n",
    "#### 기본값 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444ebc8",
   "metadata": {
    "papermill": {
     "duration": 0.009661,
     "end_time": "2022-06-25T13:35:42.490694",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.481033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 훈련 매서드인 lightgbm.train()의 파라미터\n",
    "#### params : LightGBM 모델의 하이퍼파라미터 목록\n",
    "#### 딕셔너리 타입으로 전달\n",
    "\n",
    "### train_set : 훈련 데이터 셋\n",
    "#### lightgbm.Dataset 타입으로 전달\n",
    "\n",
    "### num_boost_round : 부스팅 반복 횟수\n",
    "#### xgboost.train()의 num_boost_round와 같은 의미\n",
    "#### 기본값 = 100\n",
    "\n",
    "### valid_sets : 모델 성능 평가용 검증 데이터 셋\n",
    "#### lightgbm.Dataset 타입으로 전달\n",
    "#### 훈련을 반복하면서 훈련이 잘 되고있는지 평가할 때 사용\n",
    "#### 기본값 = None\n",
    "\n",
    "### feval : 검증용 평가지표\n",
    "#### 사용자 정의 함수 형태로 전달\n",
    "#### valid_sets를 활용해 모델 성능을 검증할 때 사용할 사용자 정의 평가 지표\n",
    "#### 예측값과 실제값을 파라미터로 전달받아, 평가지표명, 평가점수, 평가점수가 크면 좋은지 여부를 반환하는 함수여야 함\n",
    "#### 기본값 = None\n",
    "\n",
    "### categorical_feature : 범주형 데이터 파라미터\n",
    "#### 이 파라미터에 전달된 데이터를 범주형 데이터로 인식함\n",
    "#### 아무 값도 전달하지 않으면 categori 타입인 데이터를 범주형 데이터로 인식함\n",
    "\n",
    "### early_stopping_rounds : 조기종료 조건\n",
    "#### 정수형 타입으로 전달\n",
    "#### 모델은 기본적으로 num_boost_round만큼 훈련을 반복함\n",
    "#### 매 이터레이션마다 valid_sets로 모델 성능을 평가하는데, 모델 성능이 연속으로 좋아지지 않는다면 훈련을 중단함\n",
    "#### 훈련을 중단하는 데 필요한 최소 횟수가 early_stopping_rounds임 즉 early_stopping_rounds 동안 모델 성능이 좋아지지 않는다면 훈련을 중단함\n",
    "#### 과대적합을 방지하는 효과가 있음\n",
    "#### 대체로 learning_rate가 작으면 early_stopping_rounds를 크게 설정하고 learning_rate가 크면 early_stopping_rounds를 작게 설정함\n",
    "#### 기본값 = None\n",
    "\n",
    "### verbose_eval : 성능 점수 로그 설정 값\n",
    "#### xgboost.train()의 verbose_eval과 같은 의미\n",
    "\n",
    "## 사이킷런 래퍼 모듈 vs 파이썬 래퍼 모듈 차이점(162p 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3742c6e",
   "metadata": {
    "papermill": {
     "duration": 0.009913,
     "end_time": "2022-06-25T13:35:42.510590",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.500677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 하이퍼파라미터 최적화\n",
    "\n",
    "### 사용자가 직접 설정해야되는 값\n",
    "### 대표적인 최적화 방법 : 그리드서치, 랜덤서치, 베이지안 최적화\n",
    "\n",
    "## 그리드서치\n",
    "#### 가장 기본적인 하이퍼파라미터 최적화 기법 // 모든 경우의 수 탐색\n",
    "\n",
    "## 랜덤서치\n",
    "#### 하이퍼파라미터를 무작위로 탐색해 가장 좋은 성능을 내는 값을 찾는 기법\n",
    "#### 무작위라는 한계때문에 그리드서치나, 베이지안 최적화에 비해 사용빈도가 떨어짐\n",
    "\n",
    "## 베이지안 최적화\n",
    "#### 사전 정보를 바탕으로 최적 하이퍼파라미터 값을 확률적으로 추정하며 탐색하는 기법임 // 그리드서치나 랜덤서치보다 최적 하이퍼파라미터를 더 빠르고 효율적으로 찾아줌 // 코드도 직관적이라 사용하기 편함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624833ed",
   "metadata": {
    "papermill": {
     "duration": 0.00973,
     "end_time": "2022-06-25T13:35:42.530631",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.520901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## bayes_opt 패키지로 베이시안 최적화 구현\n",
    "#### 1. 하이퍼파라미터 탐색 범위 설정 : 최적값을 찾고 싶은 하이퍼파라미터의 범위 설정\n",
    "#### 2. 평가지표 계산 함수(성능 평가 함수) 정의 : 탐색하려는 하이퍼파라미터를 인수로 받아 평가지표 값을 계산해주는 함수를 정의함\n",
    "#### 3. BayesianOptimization 객체 생성 : bayes_opt 패키지의 BayesianOptimization 객체를 생성함. 객체 생성 시 '평가지표 계산 함수'와 '하이퍼파라미터 탐색 범위'를 입력받음\n",
    "#### 4. 베이지안 취적화 수행 : 3에서 생성한 BayesianOptimization 객체의 maximize() 매서드를 호출함. \n",
    "####    하이퍼파라미터 범위 내 값을 평가지표 계산 함수에 전달하면서 평가지표값을 구함 평가지표 값이 가장 좋았을때가 최적값으로 간주\n",
    "\n",
    "### 다음과 같은 간단한 예제로 베이지안 최적화를 수행\n",
    "#### 하이퍼파라미터 탐색 범위 : 'x': (-1, 5), 'y':(0,4) 평가지표 계산 함수 : -x ** 2 -(y-2)** 2 + 10 최적 하이퍼파라미터 x = 0.181, y = 2.48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd8405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:17:09.533782Z",
     "iopub.status.busy": "2022-06-25T13:17:09.533136Z",
     "iopub.status.idle": "2022-06-25T13:17:09.566003Z",
     "shell.execute_reply": "2022-06-25T13:17:09.564869Z",
     "shell.execute_reply.started": "2022-06-25T13:17:09.533648Z"
    },
    "papermill": {
     "duration": 0.009853,
     "end_time": "2022-06-25T13:35:42.550703",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.540850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1) 하이퍼파라미터 탐색 범위 설정(탐색할 하이퍼파라미터는 x와 y, 범위는 딕셔너리로 지정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbd6ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:42.573089Z",
     "iopub.status.busy": "2022-06-25T13:35:42.572404Z",
     "iopub.status.idle": "2022-06-25T13:35:42.576930Z",
     "shell.execute_reply": "2022-06-25T13:35:42.576205Z"
    },
    "papermill": {
     "duration": 0.018296,
     "end_time": "2022-06-25T13:35:42.578977",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.560681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'x' : (-1, 5) , 'y' : (0,4)} # 딕셔너리 키에 하이퍼파라미터 이름을, 값에 하이퍼파라미터 범위(튜플)를 지정하면 됨 x의 범위가 (-1,5)면 -1~5사이를 탐색하겠다는 뜻임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924301b",
   "metadata": {
    "papermill": {
     "duration": 0.010027,
     "end_time": "2022-06-25T13:35:42.599282",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.589255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2)평가지표 계산 함수 정의 // 베이지안 최적화는 평가지표 계산 함수로 구한 평가점수를 최대화하는 방향으로 하이퍼파라미터를 탐색합니다. 평가 점수가 가장 큰 값일 때의 하이퍼파라미터를 최적 하이퍼파라미터로 간주\n",
    "#### 물론 실제 최적 하이퍼파라미터는 아닐 수 있음 // 최적일 가능성이 높은 값임\n",
    "\n",
    "#### 다음은 임의로 만들어본 평가지표 계산 함수임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cecc5b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:42.622194Z",
     "iopub.status.busy": "2022-06-25T13:35:42.621783Z",
     "iopub.status.idle": "2022-06-25T13:35:42.626844Z",
     "shell.execute_reply": "2022-06-25T13:35:42.625886Z"
    },
    "papermill": {
     "duration": 0.018581,
     "end_time": "2022-06-25T13:35:42.628878",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.610297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_function(x, y):\n",
    "    return -x ** 2 - (y-2) ** 2 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7e97f6",
   "metadata": {
    "papermill": {
     "duration": 0.009912,
     "end_time": "2022-06-25T13:35:42.648660",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.638748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 베이지안 최적화 객체 생성\n",
    "#### BayesianOptimization()으로 베이지안 최적화 객체를 생성함 중요 파라미터로는 f와 pbound가 있음 f에 '최대화하려는 평가지표 계산 함수'를 전달하고, pbound에 하이퍼 파라미터 범위를 전달\n",
    "#### 더불어 random_state를 설정해 시드값을 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a526a342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:42.670544Z",
     "iopub.status.busy": "2022-06-25T13:35:42.670123Z",
     "iopub.status.idle": "2022-06-25T13:35:42.698647Z",
     "shell.execute_reply": "2022-06-25T13:35:42.697447Z"
    },
    "papermill": {
     "duration": 0.042659,
     "end_time": "2022-06-25T13:35:42.701475",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.658816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 베이지안 최적화 객채 생성\n",
    "bayesian_op = BayesianOptimization(f=eval_function,\n",
    "                                   pbounds=params,\n",
    "                                   random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5464a9c",
   "metadata": {
    "papermill": {
     "duration": 0.009812,
     "end_time": "2022-06-25T13:35:42.721688",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.711876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4)최적화 수행\n",
    "#### 최적화는 간단히 maximize() 메서드로 수행할 수 있음. 이 메서드는 여러 파라미터를 받는데, 가장 중요한 파라미터는 init_points와 n_iter임.\n",
    "\n",
    "### init_points : 랜덤 탐색을 수행할 스텝 횟수. 랜덤 탐색은 탐색 공간을 다양화 함으로써 최적화에 도움을 줄 수 있음\n",
    "\n",
    "### n_iter : 베이지안 최적화를 수행할 스템 횟수. 스텝 횟수가 많을수록 최적 값을 찾을 가능성이 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256761e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:42.743751Z",
     "iopub.status.busy": "2022-06-25T13:35:42.743381Z",
     "iopub.status.idle": "2022-06-25T13:35:44.304850Z",
     "shell.execute_reply": "2022-06-25T13:35:44.302860Z"
    },
    "papermill": {
     "duration": 1.575541,
     "end_time": "2022-06-25T13:35:44.307330",
     "exception": false,
     "start_time": "2022-06-25T13:35:42.731789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 4.002   \u001b[0m | \u001b[0m 2.293   \u001b[0m | \u001b[0m 2.861   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 3.121   \u001b[0m | \u001b[0m 2.617   \u001b[0m | \u001b[0m 2.18    \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 3.832   \u001b[0m | \u001b[0m 2.327   \u001b[0m | \u001b[0m 2.869   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 4.596   \u001b[0m | \u001b[95m 2.171   \u001b[0m | \u001b[95m 2.832   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-6.227   \u001b[0m | \u001b[0m 3.989   \u001b[0m | \u001b[0m 2.559   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 9.467   \u001b[0m | \u001b[95m 0.3522  \u001b[0m | \u001b[95m 1.361   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 7.39    \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 3.269   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 3.841   \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.966   \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 1.817   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 9.737   \u001b[0m | \u001b[95m 0.1806  \u001b[0m | \u001b[95m 2.48    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 5.785   \u001b[0m | \u001b[0m 0.4638  \u001b[0m | \u001b[0m 4.0     \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# 베이지안 최적화 수행\n",
    "bayesian_op.maximize(init_points=2, n_iter = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c4fba",
   "metadata": {
    "papermill": {
     "duration": 0.010222,
     "end_time": "2022-06-25T13:35:44.328527",
     "exception": false,
     "start_time": "2022-06-25T13:35:44.318305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 총 스텝 횟수(12)는 init_points(2)와 n_iter(10)을 합친 횟수임\n",
    "#### 중간중간 결과가 다른색으로 출력되는데, 평가 함수 점수가 기존 최댓값을 갱신했다는 뜻임 // 따라서 다른색으로 나온 결과중 가장 마지막 스텝의 평가 점수가 전체에서 최대가 되는 값임\n",
    "#### 이 결과에서는 11번째 스템으로, 베이지안 최적화로 찾은 최적의 하이퍼파라미터는 x = 0.1806 y = 2.48임 // 이 값은 베이지안 최적화 객체의 max에 저장되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fea5c49c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T13:35:44.351624Z",
     "iopub.status.busy": "2022-06-25T13:35:44.350789Z",
     "iopub.status.idle": "2022-06-25T13:35:44.358875Z",
     "shell.execute_reply": "2022-06-25T13:35:44.357774Z"
    },
    "papermill": {
     "duration": 0.022477,
     "end_time": "2022-06-25T13:35:44.361439",
     "exception": false,
     "start_time": "2022-06-25T13:35:44.338962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 9.73708754050397,\n",
       " 'params': {'x': 0.18063747442587866, 'y': 2.4798776535004214}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_op.max # 평가점수가 최대일 때 타깃, x, y값 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.589821,
   "end_time": "2022-06-25T13:35:45.094276",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-25T13:35:29.504455",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
